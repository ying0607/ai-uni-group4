import requests
import time
import json
from dotenv import load_dotenv
import os

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

def check_ollama_server(server_url=None, retries=3, retry_delay=2):
    """
    æª¢æŸ¥ Ollama ä¼ºæœå™¨é€£ç·šç‹€æ…‹ä¸¦ç²å–å¯ç”¨æ¨¡å‹åˆ—è¡¨
    
    åƒæ•¸:
        server_url (str): Ollama ä¼ºæœå™¨ URLï¼Œå¦‚æœç‚º None å‰‡å¾ç’°å¢ƒè®Šæ•¸æˆ–é»˜èªå€¼è®€å–
        retries (int): é‡è©¦æ¬¡æ•¸
        retry_delay (int): é‡è©¦é–“éš”ï¼ˆç§’ï¼‰
        
    è¿”å›:
        tuple: (é€£ç·šç‹€æ…‹ (bool), å¯ç”¨æ¨¡å‹åˆ—è¡¨ (list), éŒ¯èª¤ä¿¡æ¯ (str))
    """
    # ç²å–ä¼ºæœå™¨ URL
    if server_url is None:
        server_url = os.getenv("SERVER_URL")
        
    print(f"ä¼ºæœå™¨ URL: {server_url}")
    
    # ç¢ºä¿ URL ä»¥ http:// æˆ– https:// é–‹é ­
    if not server_url.startswith(("http://", "https://")):
        server_url = f"http://{server_url}"
    
    # ç§»é™¤å°¾éƒ¨æ–œç·š
    server_url = server_url.rstrip("/")
    
    # Ollama API ç«¯é»
    models_endpoint = f"{server_url}/api/tags"
    
    print(f"æ­£åœ¨æª¢æŸ¥ Ollama ä¼ºæœå™¨é€£ç·šç‹€æ…‹ï¼š{server_url}")
    
    # å˜—è©¦é€£æ¥
    for attempt in range(retries):
        try:
            response = requests.get(models_endpoint, timeout=5)
            
            if response.status_code == 200:
                try:
                    data = response.json()
                    models = [model.get('name') for model in data.get('models', [])]
                    
                    if models:
                        print(f"âœ… Ollama ä¼ºæœå™¨é€£ç·šæˆåŠŸï¼å¯ç”¨æ¨¡å‹ï¼š{', '.join(models)}")
                        return True, models, ""
                    else:
                        print(f"âš ï¸ Ollama ä¼ºæœå™¨é€£ç·šæˆåŠŸï¼Œä½†æœªæ‰¾åˆ°ä»»ä½•å¯ç”¨æ¨¡å‹ã€‚")
                        return True, [], "æœªæ‰¾åˆ°å¯ç”¨æ¨¡å‹"
                except json.JSONDecodeError:
                    print(f"âš ï¸ Ollama ä¼ºæœå™¨å›æ‡‰æ ¼å¼éŒ¯èª¤ã€‚")
                    return False, [], "ä¼ºæœå™¨å›æ‡‰æ ¼å¼éŒ¯èª¤"
            else:
                print(f"âš ï¸ å˜—è©¦ {attempt+1}/{retries}: ä¼ºæœå™¨å›æ‡‰ç‹€æ…‹ç¢¼ {response.status_code}")
                
        except requests.exceptions.ConnectionError:
            print(f"âš ï¸ å˜—è©¦ {attempt+1}/{retries}: ç„¡æ³•é€£æ¥åˆ° Ollama ä¼ºæœå™¨")
        except requests.exceptions.Timeout:
            print(f"âš ï¸ å˜—è©¦ {attempt+1}/{retries}: é€£æ¥è¶…æ™‚")
        except Exception as e:
            print(f"âš ï¸ å˜—è©¦ {attempt+1}/{retries}: ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤ - {str(e)}")
        
        if attempt < retries - 1:
            print(f"å°‡åœ¨ {retry_delay} ç§’å¾Œé‡è©¦...")
            time.sleep(retry_delay)
    
    print("âŒ ç„¡æ³•é€£æ¥åˆ° Ollama ä¼ºæœå™¨ã€‚è«‹ç¢ºèªä¼ºæœå™¨æ˜¯å¦é‹è¡Œï¼Œä»¥åŠ URL æ˜¯å¦æ­£ç¢ºã€‚")
    return False, [], "ç„¡æ³•é€£æ¥åˆ°ä¼ºæœå™¨"


def check_model_availability(server_url=None, model_name=None, retries=2):
    """
    æª¢æŸ¥æŒ‡å®šæ¨¡å‹åœ¨ Ollama ä¼ºæœå™¨ä¸Šæ˜¯å¦å¯ç”¨
    
    åƒæ•¸:
        server_url (str): Ollama ä¼ºæœå™¨ URL
        model_name (str): è¦æª¢æŸ¥çš„æ¨¡å‹åç¨±
        retries (int): é‡è©¦æ¬¡æ•¸
        
    è¿”å›:
        tuple: (æ¨¡å‹æ˜¯å¦å¯ç”¨ (bool), éŒ¯èª¤ä¿¡æ¯ (str))
    """
    # å…ˆæª¢æŸ¥ä¼ºæœå™¨é€£ç·š
    server_available, available_models, error_msg = check_ollama_server(server_url, retries)
    
    if not server_available:
        return False, f"ä¼ºæœå™¨é€£ç·šå¤±æ•—: {error_msg}"
    
    # ç²å–æ¨¡å‹åç¨±
    if model_name is None:
        model_name = os.getenv("MODEL_NAME")
        
    if not model_name:
        return False, "æœªæŒ‡å®šæ¨¡å‹åç¨±"
    
    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
    model_exists = any(model.lower() == model_name.lower() for model in available_models)
    
    if model_exists:
        print(f"âœ… æ¨¡å‹ '{model_name}' åœ¨ä¼ºæœå™¨ä¸Šå¯ç”¨")
        return True, ""
    else:
        error_message = f"âš ï¸ æ¨¡å‹ '{model_name}' åœ¨ä¼ºæœå™¨ä¸Šä¸å¯ç”¨ã€‚å¯ç”¨æ¨¡å‹: {', '.join(available_models)}"
        print(error_message)
        return False, error_message


# ä½¿ç”¨ç¯„ä¾‹
if __name__ == "__main__":
    # å¾ç’°å¢ƒè®Šæ•¸ç²å–
    server_url = os.getenv("SERVER_URL")
    model_name = os.getenv("MODEL_NAME")
    
    # æª¢æŸ¥ä¼ºæœå™¨é€£ç·š
    connected, models, error = check_ollama_server(server_url)
    
    if connected:
        # æª¢æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
        model_available, model_error = check_model_availability(server_url, model_name)
        
        if model_available:
            print("ğŸš€ ä¼ºæœå™¨å’Œæ¨¡å‹æª¢æŸ¥é€šéï¼Œæ‡‰ç”¨ç¨‹åºå¯ä»¥æ­£å¸¸é‹è¡Œã€‚")
        else:
            print(f"â›” æ¨¡å‹æª¢æŸ¥å¤±æ•—: {model_error}")
            # å¯ä»¥å»ºè­°ä½¿ç”¨å¯ç”¨çš„æ¨¡å‹ä¹‹ä¸€
            if models:
                print(f"ğŸ’¡ å»ºè­°ï¼šæ‚¨å¯ä»¥å˜—è©¦ä½¿ç”¨ä»¥ä¸‹å¯ç”¨æ¨¡å‹ä¹‹ä¸€: {', '.join(models)}")
                print("   æˆ–è€…ä½¿ç”¨ 'ollama pull MODEL_NAME' å‘½ä»¤ä¸‹è¼‰æ‰€éœ€æ¨¡å‹ã€‚")
    else:
        print(f"â›” ä¼ºæœå™¨é€£ç·šæª¢æŸ¥å¤±æ•—: {error}")
        print("ğŸ’¡ å»ºè­°ï¼šè«‹ç¢ºèª Ollama ä¼ºæœå™¨å·²å•Ÿå‹•ï¼Œæˆ–æª¢æŸ¥ç’°å¢ƒè®Šæ•¸ SERVER è¨­ç½®ã€‚")